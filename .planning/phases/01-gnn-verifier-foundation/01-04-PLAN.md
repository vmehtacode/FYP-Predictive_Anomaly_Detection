---
phase: 01-gnn-verifier-foundation
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - src/fyp/gnn/synthetic_dataset.py
  - tests/test_gnn/test_synthetic_dataset.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Synthetic anomaly generator creates realistic grid anomalies"
    - "Generator produces labeled training data (features, labels, graph structure)"
    - "Multiple anomaly types supported (spike, dropout, cascade, ramp violation)"
  artifacts:
    - path: "src/fyp/gnn/synthetic_dataset.py"
      provides: "Synthetic anomaly generation for GNN training"
      exports: ["SyntheticAnomalyDataset", "AnomalyType"]
      min_lines: 150
    - path: "tests/test_gnn/test_synthetic_dataset.py"
      provides: "Unit tests for synthetic dataset"
      min_lines: 80
  key_links:
    - from: "src/fyp/gnn/synthetic_dataset.py"
      to: "torch_geometric.data.Data"
      via: "import + Data construction"
      pattern: "from torch_geometric.data import Data"
    - from: "src/fyp/gnn/synthetic_dataset.py"
      to: "src/fyp/gnn/graph_builder.py"
      via: "import for graph structure"
      pattern: "from fyp.gnn.graph_builder import"
---

<objective>
Create a synthetic anomaly dataset generator for GNN training that produces labeled graph data with realistic grid anomalies.

Purpose: Close the gap "Synthetic anomaly dataset generator for training" - tests have inline mock data but no reusable generator for training/evaluation. This is required to achieve >85% accuracy on held-out synthetic anomalies.

Output: A reusable SyntheticAnomalyDataset class that generates labeled training data with multiple anomaly types (spike, dropout, cascade, ramp violation) on graph-structured grid topology.
</objective>

<execution_context>
@/Users/vatsalmehta/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vatsalmehta/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-gnn-verifier-foundation/01-01-SUMMARY.md
@.planning/phases/01-gnn-verifier-foundation/01-02-SUMMARY.md
@src/fyp/gnn/graph_builder.py
@src/fyp/gnn/gat_verifier.py
@tests/test_gnn/test_gat_verifier.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SyntheticAnomalyDataset class</name>
  <files>src/fyp/gnn/synthetic_dataset.py</files>
  <action>
Create a SyntheticAnomalyDataset class that generates labeled PyG Data objects for GNN training:

1. **AnomalyType enum**: Define anomaly types matching SSEN grid scenarios:
   - SPIKE: Sudden consumption increase (e.g., EV charging, industrial load)
   - DROPOUT: Zero consumption periods (outage, meter failure)
   - CASCADE: Anomaly propagating through connected nodes (cold snap effect)
   - RAMP_VIOLATION: Physically impossible consumption changes
   - NORMAL: Baseline non-anomalous data (for negative examples)

2. **SyntheticAnomalyDataset class**:
   - `__init__(self, num_samples, num_nodes, anomaly_ratio, temporal_features, seed)`:
     - num_samples: Total samples to generate
     - num_nodes: Nodes per graph (default matches SSEN test: 44)
     - anomaly_ratio: Fraction of samples with anomalies (default 0.5)
     - temporal_features: Input feature dimension (default 5 for time-series window)
     - seed: Random seed for reproducibility

   - `generate_sample() -> Data`: Generate one labeled sample:
     - Create random graph structure (or use template from GridGraphBuilder pattern)
     - Generate baseline features (normal consumption patterns)
     - With probability anomaly_ratio, inject anomaly:
       - Select anomaly type
       - Apply anomaly to subset of nodes
       - Set node-level labels (1 for anomalous, 0 for normal)
     - Return PyG Data with x, edge_index, y (labels), node_type

   - `__getitem__(idx) -> Data`: Return pre-generated or lazy-generated sample
   - `__len__() -> int`: Return num_samples

3. **Anomaly injection methods**:
   - `_inject_spike(x, node_mask, magnitude)`: Multiply features by magnitude (1.5-3x)
   - `_inject_dropout(x, node_mask)`: Zero out features
   - `_inject_cascade(x, edge_index, start_nodes, decay)`: Propagate anomaly through neighbors
   - `_inject_ramp_violation(x, node_mask)`: Create physically impossible gradients

4. **Physics-aware generation**:
   - Use SSEN-style constraints for realistic bounds
   - Node types (substation=0, feeder=1, household=2) affect anomaly behavior
   - Cascade anomalies respect graph topology (propagate through edges)

5. **Export in __init__.py**: Add SyntheticAnomalyDataset to fyp.gnn exports
  </action>
  <verify>
python -c "from fyp.gnn import SyntheticAnomalyDataset; ds = SyntheticAnomalyDataset(10, 20); print(f'Generated {len(ds)} samples, sample 0 has {ds[0].x.shape[0]} nodes')"
  </verify>
  <done>
SyntheticAnomalyDataset generates labeled PyG Data objects with multiple anomaly types. Generator is importable from fyp.gnn and produces samples with correct shapes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add unit tests for synthetic dataset</name>
  <files>tests/test_gnn/test_synthetic_dataset.py</files>
  <action>
Create comprehensive tests for the synthetic dataset generator:

1. **Basic generation tests**:
   - test_dataset_length(): Verify __len__ returns correct count
   - test_sample_structure(): Verify each sample has x, edge_index, y, node_type
   - test_sample_shapes(): Verify x shape is [num_nodes, temporal_features]
   - test_labels_binary(): Verify y values are 0 or 1

2. **Anomaly type tests**:
   - test_spike_anomaly(): Verify spike increases feature values
   - test_dropout_anomaly(): Verify dropout zeros features
   - test_cascade_anomaly(): Verify anomaly propagates through edges
   - test_ramp_violation(): Verify creates impossible gradients

3. **Ratio and distribution tests**:
   - test_anomaly_ratio(): Verify ~50% samples have anomalies when ratio=0.5
   - test_reproducibility(): Same seed produces same samples
   - test_node_label_distribution(): Some nodes labeled anomalous, some normal

4. **Integration with GATVerifier**:
   - test_dataloader_compatibility(): Verify works with torch_geometric DataLoader
   - test_batch_creation(): Verify Batch.from_data_list works
   - test_model_forward(): Verify GATVerifier can process generated samples

5. **Edge cases**:
   - test_small_graph(): Handle graphs with <10 nodes
   - test_no_anomalies(): Handle anomaly_ratio=0
   - test_all_anomalies(): Handle anomaly_ratio=1

Use pytest fixtures for reusable test setup. Follow existing test patterns from test_gat_verifier.py.
  </action>
  <verify>
pytest tests/test_gnn/test_synthetic_dataset.py -v --tb=short
  </verify>
  <done>
All unit tests pass. Synthetic dataset generator is thoroughly tested for correctness, anomaly injection, and GATVerifier compatibility.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from fyp.gnn import SyntheticAnomalyDataset"` succeeds
2. `pytest tests/test_gnn/test_synthetic_dataset.py -v` all pass
3. Generated samples have correct PyG Data structure (x, edge_index, y, node_type)
4. Anomaly ratio approximately matches configured value
5. GATVerifier can process generated samples without errors
</verification>

<success_criteria>
- SyntheticAnomalyDataset class exists with 5 anomaly types
- Generator produces PyG-compatible Data objects
- Labels correctly identify anomalous nodes
- All tests pass (target: 15+ tests)
- Works with torch_geometric DataLoader for batching
</success_criteria>

<output>
After completion, create `.planning/phases/01-gnn-verifier-foundation/01-04-SUMMARY.md`
</output>
